# Text Summarization with PEGASUS

An end-to-end text summarization system using the PEGASUS model from Hugging Face Transformers. This project implements a complete pipeline from data ingestion to model deployment with FastAPI.

## ğŸš€ Features

- **End-to-End Pipeline**: Data ingestion, validation, transformation, model training, and evaluation
- **Pre-trained Model**: Utilizes Google's PEGASUS model fine-tuned on the SAMSum dataset
- **REST API**: FastAPI-based web service for model inference
- **Containerized**: Docker support for easy deployment
- **CI/CD**: GitHub Actions workflow for automated testing and deployment
- **Model Persistence**: Saves and loads models locally to avoid retraining

## ğŸ“¦ Prerequisites

- Python 3.9+
- pip
- Git
- Docker (optional, for containerization)
- AWS Account (for ECR deployment, optional)

## ğŸ›  Installation

1. **Clone the repository**
   ```bash
   git clone https://github.com/Harshgoyal2004/text_summarisation.git
   cd text_summarisation
   ```

2. **Create and activate a virtual environment**
   ```bash
   python -m venv venv
   source venv/bin/activate  # On Windows: venv\Scripts\activate
   ```

3. **Install dependencies**
   ```bash
   pip install -r requirements.txt
   pip install -e .
   ```

## ğŸƒâ€â™‚ï¸ Quick Start

1. **Run the training pipeline**
   ```bash
   python main.py
   ```
   This will execute the complete pipeline:
   - Data Ingestion
   - Data Validation
   - Data Transformation
   - Model Training
   - Model Evaluation

2. **Start the FastAPI server**
   ```bash
   uvicorn app:app --reload
   ```

3. **Make predictions**
   ```bash
   curl -X 'POST' \
     'http://localhost:8000/predict' \
     -H 'Content-Type: text/plain' \
     -d 'Your long text to be summarized goes here...'
   ```

## ğŸ³ Docker Support

Build the Docker image:
```bash
docker build -t text-summarization .
```

Run the container:
```bash
docker run -p 8000:8000 text-summarization
```

## ğŸ“‚ Project Structure

```
text_summarisation/
â”œâ”€â”€ artifacts/                     # Stores processed data, models, and outputs
â”‚   â”œâ”€â”€ data_ingestion/           # Raw and processed data
â”‚   â”œâ”€â”€ data_transformation/      # Transformed datasets
â”‚   â”œâ”€â”€ model_evaluation/         # Evaluation metrics
â”‚   â””â”€â”€ model_trainer/            # Trained models
â”œâ”€â”€ config/                       # Configuration files
â”‚   â”œâ”€â”€ config.yaml              # Main configuration
â”‚   â””â”€â”€ params.yaml              # Hyperparameters
â”œâ”€â”€ src/                          # Source code
â”‚   â””â”€â”€ textSummarizer/
â”‚       â”œâ”€â”€ components/           # Pipeline components
â”‚       â”œâ”€â”€ config/               # Configuration management
â”‚       â”œâ”€â”€ entity/               # Data classes
â”‚       â”œâ”€â”€ logging/              # Logging configuration
â”‚       â”œâ”€â”€ pipeline/             # Pipeline stages
â”‚       â””â”€â”€ utils/                # Utility functions
â”œâ”€â”€ .github/workflows/            # CI/CD workflows
â”œâ”€â”€ app.py                       # FastAPI application
â”œâ”€â”€ Dockerfile                   # Container configuration
â”œâ”€â”€ main.py                      # Main pipeline
â””â”€â”€ requirements.txt             # Dependencies
```

## ğŸ¤– Model Details

- **Base Model**: PEGASUS (Pre-training with Extracted Gap-sentences for Abstractive Summarization)
- **Dataset**: SAMSum (conversation summarization)
- **Training**: Fine-tuned on a single GPU
- **Inference**: Supports both CPU and GPU

## ğŸŒ API Endpoints

- `POST /predict`: Generate summary from input text
  - Content-Type: `text/plain`
  - Returns: Plain text summary

- `GET /train`: Trigger model training
  - Returns: Training status

- `GET /`: Health check
  - Returns: API status

## ğŸ”§ Configuration

Edit `config/config.yaml` to modify:
- Dataset paths
- Model parameters
- Training settings
- Evaluation metrics

## ğŸš€ Deployment

The project includes a GitHub Actions workflow (`.github/workflows/main.yaml`) for CI/CD that:
1. Runs tests
2. Builds and pushes Docker image to AWS ECR
3. Deploys to a self-hosted runner

## ğŸ¤ Contributing

1. Fork the repository
2. Create a feature branch
3. Commit your changes
4. Push to the branch
5. Create a new Pull Request

## ğŸ“ License

This project is licensed under the MIT License - see the [LICENSE](LICENSE) file for details.

## ğŸ“š Resources

- [Hugging Face Transformers](https://huggingface.co/transformers/)
- [PEGASUS Paper](https://arxiv.org/abs/1912.08777)
- [FastAPI Documentation](https://fastapi.tiangolo.com/)
- [Docker Documentation](https://docs.docker.com/)
8. Update the app.py